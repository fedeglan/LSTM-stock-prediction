#1-Import basic libraries 
import pandas as pd
import yfinance as yf
import numpy as np
import matplotlib.pyplot as plt
%matplotlib inline

#2-Download stock data
data=yf.download('AAPL')[['Adj Close']]
data.reset_index(inplace=True)
data.drop('Date', axis=1, inplace=True)

#3-Data pre-processing 

#Split into train and test set
split_percentage=0.9
split_point=round(len(data)*split_percentage)
train_data=data.iloc[:split_point]
test_data=data.iloc[split_point:]

#Scale the data
from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler()
scaler.fit(train_data)
scaled_train = scaler.transform(train_data)
scaled_test = scaler.transform(test_data)

#4-Transform the data to use it like a time series, Xs will have a shape of (#Samples, #Lags) and Ys of (#Samples,)
def timeseries_preprocessing(scaled_train, scaled_test, lags):
    X,Y = [],[]
    for t in range(len(scaled_train)-lags-1):
        X.append(scaled_train[t:(t+lags),0])
        Y.append(scaled_train[(t+lags),0])
    
    Z,W = [],[]
    for t in range(len(scaled_test)-lags-1):
        Z.append(scaled_test[t:(t+lags),0])
        W.append(scaled_test[(t+lags),0])
        
    X_train, Y_train, X_test, Y_test=np.array(X), np.array(Y), np.array(Z),np.array(W)
    
    #Reshape Xs as (Sample,Timestep,Features), reshape is necessary for keras to understand
    X_train = X_train.reshape((X_train.shape[0],X_train.shape[1],1))
    X_test = X_test.reshape((X_test.shape[0],X_test.shape[1],1))
    
    return X_train, Y_train, X_test, Y_test

X_train, Y_train, X_test, Y_test=timeseries_preprocessing(scaled_train, scaled_test, 10)

#5-Create the model
from tensorflow.keras.models import Sequential 
from tensorflow.keras.layers import Dense, LSTM

model = Sequential()
model.add(LSTM(256,input_shape=(X_train.shape[1],1)))
model.add(Dense(1))
model.compile(optimizer='adam',loss='mse')

#6-Fit model with history to check for overfitting
history = model.fit(x=X_train,y=Y_train,epochs=300,validation_data=(X_test,Y_test),shuffle=False)

#7-Evaluate the model
Y_predicted=scaler.inverse_transform(model.predict(X_test))
Y_true=scaler.inverse_transform(Y_test.reshape(Y_test.shape[0],1))

fig,axes=plt.subplots(1,2,figsize=(12,4))
axes[0].plot(pd.DataFrame(model.history.history)['loss'], label='Loss')
axes[0].plot(pd.DataFrame(model.history.history)['val_loss'], label='Validation Loss')
axes[0].legend(loc=0)
axes[0].set_title('Model fitting performance')

axes[1].plot(Y_true, label='True Y')
axes[1].plot(Y_predicted, label='Predicted Y')
axes[1].legend(loc=0)
axes[1].set_title('Prediction adjustment')

from sklearn import metrics
print('Model accuracy (MSE % with train data)')
Y_p=scaler.inverse_transform(model.predict(X_train))
Y_t=scaler.inverse_transform(Y_train.reshape(Y_train.shape[0],1))
print((metrics.mean_absolute_error(Y_t, Y_p)/Y_t.mean())*100)
print('')
print('Prediction performance')
print('MAE in %', (metrics.mean_absolute_error(Y_true, Y_predicted)/Y_true.mean())*100)
print('MSE', metrics.mean_squared_error(Y_true, Y_predicted))
print('RMSE',np.sqrt(metrics.mean_squared_error(Y_true, Y_predicted)))
print('R2', metrics.r2_score(Y_true, Y_predicted))
